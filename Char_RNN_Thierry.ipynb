{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Char RNN Thierry.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyON+45yfu0YIiNBYL7dTZMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smartsie/Playground/blob/master/Char_RNN_Thierry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "YEmDGnkjT9F6",
        "outputId": "4cf79695-4644-4c9c-90db-a5c1f9e7be69"
      },
      "source": [
        "\"\"\"\n",
        "This code is just for fun to make a text generator by myself, inspired by Karpathy but completely made up by myself\n",
        "T Martin, 12/11/2021\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nThis code is just for fun to make a text generator by myself, inspired by Karpathy but completely made up by myself\\nT Martin, 12/11/2021\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ozaldD70YV"
      },
      "source": [
        "# Import base libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj56iTM0UAyD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import base64\n",
        "import requests\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAy8oEOx8CY8"
      },
      "source": [
        "# Get Text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Se4TmZTjlkY"
      },
      "source": [
        "def get_text(url):\n",
        "  '''\n",
        "    The function get_text will load a txt file at the specified url\n",
        "\n",
        "    Args:\n",
        "        url: The url where the text is located. \n",
        "\n",
        "    Returns:\n",
        "        req!: a clean text\n",
        "  '''\n",
        "\n",
        "  req = requests.get(url)\n",
        "  req = req.text\n",
        "  return req"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKO_k7T1UA0Y"
      },
      "source": [
        "# Import the big text data\n",
        "url = \"http://f8cho.free.fr/RABELAIS.txt\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfY0BBFwjlmy"
      },
      "source": [
        "text=get_text(url)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVomvj24sh59"
      },
      "source": [
        "shakespeare_url='https://homl.info/shakespeare'\n",
        "filepath=tf.keras.utils.get_file('shakespeare.txt',shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "  shakespeare_text=f.read()\n",
        "text=shakespeare_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epmDBhFd8JKv"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlhnaCn0mujn"
      },
      "source": [
        "tokenizer=keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(text)\n",
        "max_id=len(tokenizer.word_index)\n",
        "dataset_size=tokenizer.document_count\n",
        "[encoded]=np.array(tokenizer.texts_to_sequences([text]))-1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK5Dh8ZImumc"
      },
      "source": [
        "train_size=dataset_size*90//100\n",
        "dataset=tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "# Transform datecaset by using windows\n",
        "n_steps=100\n",
        "window_length=n_steps+1\n",
        "dataset=dataset.window(window_length, shift=1,drop_remainder=True)\n",
        "dataset=dataset.flat_map(lambda window: window.batch(window_length))\n",
        "# Shuffle the dataset with a batch size\n",
        "batch_size=32\n",
        "dataset=dataset.shuffle(10000).batch(batch_size)\n",
        "dataset=dataset.map(lambda windows: (windows[:,:-1],windows[:,1:]))\n",
        "# One hot encoding\n",
        "dataset=dataset.map(\n",
        "    lambda X_batch,Y_batch: (tf.one_hot(X_batch,depth=max_id),Y_batch)\n",
        ")\n",
        "# prefetching\n",
        "dataset=dataset.prefetch(1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrm8Jp8f8SGC"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGFwJuhQmuo8"
      },
      "source": [
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.GRU(128,return_sequences=True,input_shape=[None,max_id],dropout=0.2,recurrent_dropout=0.2),\n",
        "    tf.keras.layers.GRU(128,return_sequences=True,dropout=0.2,recurrent_dropout=0.2),\n",
        "    tf.keras.layers.TimeDistributed(keras.layers.Dense(max_id,activation='softmax'))    \n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1C6CNC2murn",
        "outputId": "f00dd81b-27c9-4a4a-9f46-72e69a51fe5f"
      },
      "source": [
        "model.fit(dataset,epochs=10,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "934/934 [==============================] - 462s 488ms/step - loss: 2.2393\n",
            "Epoch 2/10\n",
            "934/934 [==============================] - 457s 487ms/step - loss: 1.7193\n",
            "Epoch 3/10\n",
            "934/934 [==============================] - 456s 486ms/step - loss: 1.5395\n",
            "Epoch 4/10\n",
            "934/934 [==============================] - 457s 487ms/step - loss: 1.4356\n",
            "Epoch 5/10\n",
            "934/934 [==============================] - 459s 489ms/step - loss: 1.3658\n",
            "Epoch 6/10\n",
            "934/934 [==============================] - 464s 495ms/step - loss: 1.3139\n",
            "Epoch 7/10\n",
            "934/934 [==============================] - 455s 485ms/step - loss: 1.2736\n",
            "Epoch 8/10\n",
            "934/934 [==============================] - 451s 481ms/step - loss: 1.2413\n",
            "Epoch 9/10\n",
            "934/934 [==============================] - 447s 477ms/step - loss: 1.2134\n",
            "Epoch 10/10\n",
            "584/934 [=================>............] - ETA: 2:50 - loss: 1.2030"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DEasHAfTpSJ"
      },
      "source": [
        "# Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqr1rP9kqb78"
      },
      "source": [
        "def preprocess(texts):\n",
        "  X=np.array(tokenizer.texts_to_sequences(texts))-1\n",
        "  return tf.one_hot(X,max_id)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBGdCT5BjlsE"
      },
      "source": [
        "def next_char(text,temperature=1):\n",
        "  X_new=preprocess([text])\n",
        "  y_proba=model.predict(X_new)[0,-1:,:]\n",
        "  rescaled_logits=tf.math.log(y_proba)/temperature\n",
        "  char_id=tf.random.categorical(rescaled_logits, num_samples=1)+1\n",
        "  return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_BMFyff3Gq-"
      },
      "source": [
        "def complete_text(text,n_chars=500,temperature=1):\n",
        "  for _ in range(n_chars):\n",
        "    text+=next_char(text,temperature)\n",
        "  return text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44b21Ahp4K7m",
        "outputId": "a924bc56-62f2-4316-da59-5f56f7df4c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "result=complete_text(\"Pantagruel \",temperature=1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fbb4dd717556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplete_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pantagruel \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-6c6b2a83905d>\u001b[0m in \u001b[0;36mcomplete_text\u001b[0;34m(text, n_chars, temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomplete_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_chars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-028c6dae9f21>\u001b[0m in \u001b[0;36mnext_char\u001b[0;34m(text, temperature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnext_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mX_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0my_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mrescaled_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mchar_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescaled_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-61c8aa9666da>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-hzA85K4v4k",
        "outputId": "42302980-0c70-4bd2-9228-162f7a4579ac"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pantagruel cetture es de commes avact de pan la qu'il nonnêqr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUxeZ6j45M0Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}